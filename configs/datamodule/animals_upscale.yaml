_target_: src.datamodules.images.ImageDataModule
_convert_: object

train_set:
  _target_: src.datamodules.images.ImageUpscaleDataset
  _partial_: True
  dataset:
    _target_: torchvision.datasets.ImageFolder
    _partial_: True
    root: ${paths.data_dir}/afhq_v2/train
    transform:
      _target_: torchvision.transforms.Compose
      transforms:
        - _target_: torchvision.transforms.PILToTensor
        - _target_: torchvision.transforms.Resize
          size: 280
        - _target_: torchvision.transforms.RandomCrop
          size: 256
        - _target_: torchvision.transforms.RandomHorizontalFlip
        - _target_: torchvision.transforms.ConvertImageDtype
          dtype:
            _target_: mattstools.mattstools.torch_utils.dtype_lookup
            dtype: float

test_set:
  _target_: ${..train_set._target_}
  _partial_: True
  dataset:
    _target_: ${...train_set.dataset._target_}
    _partial_: True
    root: ${paths.data_dir}/afhq_v2/test
    transform:
      _target_: torchvision.transforms.Compose
      transforms:
        - _target_: torchvision.transforms.PILToTensor
        - _target_: torchvision.transforms.Resize
          size: 280
        - _target_: torchvision.transforms.CenterCrop
          size: 256
        - _target_: torchvision.transforms.ConvertImageDtype
          dtype:
            _target_: mattstools.mattstools.torch_utils.dtype_lookup
            dtype: float

loader_config:
  pin_memory: true
  batch_size: 64
  num_workers: 8
  drop_last: True
  shuffle: True
